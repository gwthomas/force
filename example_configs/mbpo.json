{
  "algorithm": "MBPO",
  "initial_steps": 5000,
  "wrapper": {
    "updates_per_iter": 1000
  },
  "agent": {
    "_tag": "MBPO",
    "model": {
      "ensemble": {
        "num_models": 5,
        "num_hidden_layers": 4,
        "hidden_dim": 200
      },
      "optimizer": {
        "algorithm": "AdamW",
        "lr": 0.001
      },
      "batch_size": 256
    },
    "solver": {
      "critic": {
        "ensemble": {
          "num_models": 2
        }
      },
      "critic_optimizer": {
        "algorithm": "Adam",
        "lr": 3e-4
      },
      "actor_optimizer": {
        "algorithm": "Adam",
        "lr": 3e-4
      },
      "batch_size": 256
    }
  }
}