{
  "algorithm": "MBPO",
  "initial_steps": 5000,
  "wrapper": {
    "updates_per_iter": 1000
  },
  "agent": {
    "_tag": "MBPO",
    "model": {
      "ensemble": {
        "num_models": 5,
        "num_hidden_layers": 4,
        "hidden_dim": 200
      }
    },
    "model_trainer": {
      "optimizer": {
        "algorithm": "AdamW",
        "lr": 0.001
      }
    },
    "solver": {
      "critic_optimizer": {
        "algorithm": "Adam",
        "lr": 3e-4
      },
      "actor_optimizer": {
        "algorithm": "Adam",
        "lr": 3e-4
      }
    }
  }
}